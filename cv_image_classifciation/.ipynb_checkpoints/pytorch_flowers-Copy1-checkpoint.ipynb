{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 30\n",
    "LEARNING_RATE = 0.003\n",
    "IMG_SIZE = 64\n",
    "CONV_SIZE = math.floor((((IMG_SIZE-2)/2)-2)/2)\n",
    "\n",
    "TRAIN_DATA_PATH = \"C:/Users/Administrator/Desktop/programming/datasets/images/flowers_train_test/train\"\n",
    "TEST_DATA_PATH = \"C:/Users/Administrator/Desktop/programming/datasets/images/flowers_train_test/test\"\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3813\n",
      "510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble_Net(\n",
       "  (e1): Flower_Net_1(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): AvgPool2d(kernel_size=3, stride=3, padding=1)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (flatten): Flatten()\n",
       "  )\n",
       "  (e2): Flower_Net_2(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): AvgPool2d(kernel_size=3, stride=3, padding=1)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (flatten): Flatten()\n",
       "  )\n",
       "  (e3): Flower_Net_3(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): AvgPool2d(kernel_size=3, stride=3, padding=1)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (flatten): Flatten()\n",
       "  )\n",
       "  (avgpool): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
       "  (fc1): Linear(in_features=216, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Flower_Net_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flower_Net_1,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3,8,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(8,16,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(16,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        out = self.flatten(x)\n",
    "        return out\n",
    "\n",
    "class Flower_Net_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flower_Net_2,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3,16,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(16,32,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(32,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        out = self.flatten(x)\n",
    "        return out\n",
    "    \n",
    "class Flower_Net_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flower_Net_3,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3,32,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(32,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(8,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        out = self.flatten(x)\n",
    "        return out\n",
    "\n",
    "class ensemble_Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(ensemble_Net,self).__init__()\n",
    "        f1 = Flower_Net_1()\n",
    "        f2 = Flower_Net_2()\n",
    "        f3 = Flower_Net_3()\n",
    "        self.e1 = f1\n",
    "        self.e2 = f2\n",
    "        self.e3 = f3\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=1)\n",
    "        self.fc1 = nn.Linear(216,30)\n",
    "        self.fc2 = nn.Linear(30,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        o1 = self.e1(x)\n",
    "    \n",
    "        o2 = self.e2(x)\n",
    "        o3 = self.e3(x)\n",
    "        x = torch.cat((o1,o2,o3),dim=1)\n",
    "        #print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "        \n",
    "model = ensemble_Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE, weight_decay=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "TARGET:  tensor([0, 3, 3, 2, 0, 3, 2, 0, 2, 3, 1, 1, 4, 4, 3, 0, 4, 1, 1, 0, 4, 0, 2, 2,\n",
      "        2, 2, 1, 1, 2, 4])\n",
      "OUTPUT:  tensor([0, 3, 3, 4, 0, 0, 4, 1, 4, 4, 1, 0, 2, 2, 3, 4, 0, 1, 1, 0, 1, 4, 2, 4,\n",
      "        1, 2, 1, 4, 2, 4])\n",
      "Accuracy after  50 steps:  0.5466666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-97be8bf44568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c233bcc758c4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mo2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mo3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m#print(x.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c233bcc758c4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    acc = 0.0\n",
    "    \n",
    "    print(\"Training....\")\n",
    "    model.train()\n",
    "    \n",
    "    for batch_num,(X_train,y_train) in enumerate(train_data_loader):\n",
    "        inp,target = X_train.to(DEVICE),y_train.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(inp)\n",
    "        \n",
    "        op = F.softmax(output,dim=1)\n",
    "        \n",
    "        final_op = torch.argmax(op,dim=1)\n",
    "    \n",
    "        acc += torch.sum(final_op==target).item()/len(target)\n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+=(loss.item()/len(batch))\n",
    "        if batch_num%50 ==0 and batch_num!=0:\n",
    "            print(\"TARGET: \",target)\n",
    "            print(\"OUTPUT: \",final_op)\n",
    "            print(\"Accuracy after \",batch_num,\"steps: \",acc/batch_num)\n",
    "        \n",
    "    \n",
    "    acc = acc/len(train_data_loader)\n",
    "    print(\"Epoch: \",epoch,\"Loss: \",train_loss,\" Accuracy: \",acc)\n",
    "    \n",
    "    \n",
    "    eval_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Validating.....\")\n",
    "    for batch in test_data_loader:\n",
    "        inp,target = batch[0].to(DEVICE),batch[1].to(DEVICE)\n",
    "        op = F.softmax(model.forward(inp))\n",
    "        final_op = torch.argmax(op,dim=1)\n",
    "        \n",
    "        eval_acc += np.sum(final_op.detach().cpu().numpy()==target.detach().cpu().numpy())/len(target)\n",
    "        \n",
    "    print(\"Validation accuracy: \",eval_acc/len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNmodel = ConvolutionalNetwork()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(CNNmodel.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvolutionalNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 8, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(8, 16, 3, 1)\n",
    "#         self.fc1 = nn.Linear(CONV_SIZE**2*16, 256)\n",
    "#         self.fc2 = nn.Linear(256, 64)\n",
    "#         self.fc3 = nn.Linear(64, 5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = x.view(-1, CONV_SIZE**2*16)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         x = F.log_softmax(x, dim=1)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# train_loss = []\n",
    "# test_loss = []\n",
    "# train_correct = []\n",
    "# test_correct = []\n",
    "\n",
    "# for i in range(EPOCHS):\n",
    "#     train_count = 0\n",
    "#     test_count = 0\n",
    "    \n",
    "#     for b, (X_train, y_train) in enumerate(train_data_loader):\n",
    "        \n",
    "#         b+=1\n",
    "        \n",
    "#         y_pred = CNNmodel(X_train)\n",
    "#         loss = criterion(y_pred, y_train)\n",
    " \n",
    "#         predicted = torch.max(y_pred.data, 1)[1]\n",
    "#         batch_corr = (predicted == y_train).sum()\n",
    "#         train_count += batch_corr\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if b%30 == 0:\n",
    "#             print(f'epoch: {i}   batch: {int(b/30)}   loss: {loss.item():.6f}')\n",
    "\n",
    "#     train_loss.append(loss)\n",
    "#     train_correct.append(train_count)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for b, (X_test, y_test) in enumerate(test_data_loader):\n",
    "            \n",
    "#             y_val = CNNmodel(X_test)\n",
    "\n",
    "#             predicted = torch.max(y_val.data, 1)[1] \n",
    "#             test_count += (predicted == y_test).sum()\n",
    "\n",
    "#     loss = criterion(y_val, y_test)\n",
    "#     test_loss.append(loss)\n",
    "#     test_correct.append(test_count)\n",
    "\n",
    "# print(f'\\nTime: {time.time() - start_time:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNNmodel.state_dict(), 'cnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(test_loss, label='test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_correct, label='train correct')\n",
    "plt.plot(test_correct, label='test correct')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
